{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPE Automation applied to EDDK\n",
    "\n",
    "This notebook brings together the functionality of the `GRAPE_traffic` library with GRAPE. It does the following:\n",
    "\n",
    "1. defines the airport of interest, as well as start and end times to create studies (as the traffic library loads everything into memory, we split the data per month. The raw data for a single month contains more than 2GB of data).\n",
    "2. if processed data is already cached, it is loaded and steps 3. to 9. are skipped.\n",
    "3. fetches the airport traffic data, based on the bounding box defined in the *GRAPE_traffic.conf* file.\n",
    "4. cleans any invalid data (nan values, outliers, duplicates).\n",
    "5. writes flight features to *flights unclean.csv*.\n",
    "6. performs integrity checks on each flight (aligned with a runway, has an ANP aircraft, ...).\n",
    "7. writes flight features to *flights clean.csv*.\n",
    "8. computes thrust.\n",
    "9. saves data to cache.\n",
    "10. for aircraft discarded in the filtering process, tries to find substitutes.\n",
    "11. creates a GRAPE study and inserts the data into it, adds scenarios and calculation runs to the study.\n",
    "12. calls GRAPE.exe and executes all the runs.\n",
    "13. reads the outputs in the GRAPE study and transforms it to *.csv* files containing noise results per flight/receptor and emissions results per flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from GRAPE_traffic import (\n",
    "    AirportOpensky,\n",
    "    AirportTraffic,\n",
    "    GrapeTraffic,\n",
    ")\n",
    "from GRAPE_traffic.GrapeTraffic import (\n",
    "    emissions_id,\n",
    "    emissions_id_lto_cycle,\n",
    "    noise_id,\n",
    "    performance_id,\n",
    "    scenario_id,\n",
    ")\n",
    "\n",
    "start_times = [\n",
    "    \"2019-01-01 00:00:00\",\n",
    "    \"2019-02-01 00:00:00\",\n",
    "    \"2019-03-01 00:00:00\",\n",
    "    \"2019-04-01 00:00:00\",\n",
    "    \"2019-05-01 00:00:00\",\n",
    "    \"2019-06-01 00:00:00\",\n",
    "    \"2019-07-01 00:00:00\",\n",
    "    \"2019-08-01 00:00:00\",\n",
    "    \"2019-09-01 00:00:00\",\n",
    "    \"2019-10-01 00:00:00\",\n",
    "    \"2019-11-01 00:00:00\",\n",
    "    \"2019-12-01 00:00:00\",\n",
    "]\n",
    "\n",
    "stop_times = [\n",
    "    \"2019-01-31 23:59:59\",\n",
    "    \"2019-02-28 23:59:59\",\n",
    "    \"2019-03-31 23:59:59\",\n",
    "    \"2019-04-30 23:59:59\",\n",
    "    \"2019-05-31 23:59:59\",\n",
    "    \"2019-06-30 23:59:59\",\n",
    "    \"2019-07-31 23:59:59\",\n",
    "    \"2019-08-31 23:59:59\",\n",
    "    \"2019-09-30 23:59:59\",\n",
    "    \"2019-10-31 23:59:59\",\n",
    "    \"2019-11-30 23:59:59\",\n",
    "    \"2019-12-31 23:59:59\",\n",
    "]\n",
    "\n",
    "airport = \"EDDK\"\n",
    "\n",
    "output_folder = Path(\"out/eddk\")\n",
    "\n",
    "path_flights_unclean = output_folder / \"flights unclean.csv\"\n",
    "path_flights_clean = output_folder / \"flights clean.csv\"\n",
    "path_flights_substitutes = output_folder / \"flights substitutes.csv\"\n",
    "path_flights_emissions = output_folder / \"flights emissions.csv\"\n",
    "path_noise_events = output_folder / \"noise events.csv\"\n",
    "path_noise_thresholds = \"data/EDDK 2019/Noise Thresholds.xlsx\"\n",
    "\n",
    "fill_invalid_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_traffic(airport: str, start_time: str, stop_time: str) -> AirportTraffic:\n",
    "    path = output_folder / f\"{airport}_{start_time}_{stop_time}\"\n",
    "\n",
    "    print(f\"Getting data for {airport} from {start_time} to {stop_time}\")\n",
    "\n",
    "    if path.exists():\n",
    "        return AirportTraffic.from_folder(path)\n",
    "\n",
    "    apt = AirportOpensky(airport, start_time, stop_time)\n",
    "    arr = apt.fetch_arrivals()\n",
    "    dep = apt.fetch_departures()\n",
    "\n",
    "    print(\"Cleaning data...\")\n",
    "    apt_traffic = (\n",
    "        AirportTraffic(arr, dep)\n",
    "        .clean()\n",
    "        .assign_ids(id_postfix=f\"{pd.to_datetime(start_time).month:02d}\")\n",
    "        .cumulative_distance()\n",
    "    )\n",
    "    f = apt_traffic.list_all()\n",
    "\n",
    "    if f is not None:\n",
    "        header_unclean = not path_flights_unclean.exists()\n",
    "\n",
    "        f.to_csv(path_flights_unclean, index=False, header=header_unclean, mode=\"a\")\n",
    "\n",
    "    apt_traffic = apt_traffic.clean_arrivals().clean_departures()\n",
    "    f = apt_traffic.list_all()\n",
    "\n",
    "    if f is not None:\n",
    "        header_clean = not path_flights_clean.exists()\n",
    "\n",
    "        f.to_csv(path_flights_clean, index=False, header=header_clean, mode=\"a\")\n",
    "\n",
    "    print(\"Computing Thrust...\")\n",
    "    apt_traffic.compute_thrust()\n",
    "\n",
    "    apt_traffic.save(path)\n",
    "    return apt_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_invalid(month: int) -> pd.Series:\n",
    "    print(\"Filling invalid flights...\")\n",
    "\n",
    "    def get_od(row):\n",
    "        return row[\"origin\"] if row[\"operation\"] == \"Arrival\" else row[\"destination\"]\n",
    "\n",
    "    all = pd.read_csv(path_flights_unclean)\n",
    "    all[\"month\"] = all[\"flight_id\"].str.extract(r\"\\w{3}(\\d+)_.*\", expand=False).astype(int)\n",
    "    all = all.loc[all[\"month\"] == month]\n",
    "    all[\"time\"] = pd.to_datetime(all[\"time\"], utc=True)\n",
    "    all[\"od\"] = all.apply(get_od, axis=\"columns\")\n",
    "\n",
    "    valid = pd.read_csv(path_flights_clean)\n",
    "    valid[\"month\"] = valid[\"flight_id\"].str.extract(r\"\\w{3}(\\d+)_.*\", expand=False).astype(int)\n",
    "    valid = valid.loc[valid[\"month\"] == month]\n",
    "    valid[\"time\"] = pd.to_datetime(valid[\"time\"], utc=True)\n",
    "    valid[\"od\"] = valid.apply(get_od, axis=\"columns\")\n",
    "    valid = valid.drop(columns=[\"origin\", \"destination\", \"go_around\", \"changed_runway\"])\n",
    "\n",
    "    invalid = all.loc[~all[\"flight_id\"].isin(valid[\"flight_id\"])]\n",
    "\n",
    "    # Remove flights which can't be filled and get od\n",
    "    invalid = invalid.dropna(subset=[\"runway\", \"icao24\", \"aircraft_id\"])\n",
    "    invalid = invalid.loc[invalid[\"anp_power_param\"].isin([\"CNT (lb)\", r\"CNT (% of Max Static Thrust)\"])]\n",
    "    invalid = invalid.drop(\n",
    "        columns=[\n",
    "            \"origin\",\n",
    "            \"destination\",\n",
    "            \"go_around\",\n",
    "            \"changed_runway\",\n",
    "            \"anp\",\n",
    "            \"anp_power_param\",\n",
    "            \"month\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def get_closest_flight(df):\n",
    "        return df.loc[\n",
    "            (df[\"time\"] - df[\"time_new\"]).abs().idxmin(),\n",
    "            [\"flight_id\", \"flight_id_new\"],\n",
    "        ]\n",
    "\n",
    "    rules = [\n",
    "        [\"operation\", \"runway\", \"icao24\", \"od\"],\n",
    "        [\"operation\", \"runway\", \"aircraft_id\", \"od\"],\n",
    "        [\"operation\", \"runway\", \"icao24\"],\n",
    "        [\"operation\", \"runway\", \"aircraft_id\"],\n",
    "    ]\n",
    "\n",
    "    substitutes = []\n",
    "\n",
    "    for i, rule in enumerate(rules):\n",
    "        df = (\n",
    "            invalid.merge(valid.dropna(subset=rule), on=rule, suffixes=(\"\", \"_new\"))\n",
    "            .groupby(\"flight_id\")\n",
    "            .apply(get_closest_flight)\n",
    "        )\n",
    "        df[\"rule\"] = i\n",
    "\n",
    "        substitutes.append(df)\n",
    "\n",
    "    substitutes = pd.concat(substitutes, ignore_index=True).drop_duplicates(subset=\"flight_id\")\n",
    "    header_substitutes = not path_flights_substitutes.exists()\n",
    "    substitutes.to_csv(\n",
    "        path_flights_substitutes,\n",
    "        header=header_substitutes,\n",
    "        mode=\"a\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    counts = substitutes[\"flight_id_new\"].value_counts()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_time_str, stop_time_str in zip(start_times, stop_times):\n",
    "    start_time = pd.to_datetime(start_time_str).tz_localize(\"UTC\")\n",
    "    stop_time = pd.to_datetime(stop_time_str).tz_localize(\"UTC\")\n",
    "    start_time_str = start_time.strftime(\"%Y-%m-%d\")\n",
    "    stop_time_str = stop_time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get airport traffic\n",
    "    apt_traffic = get_airport_traffic(airport, start_time_str, stop_time_str)\n",
    "\n",
    "    # Get operation count to fill invalid flights\n",
    "    if fill_invalid_flag:\n",
    "        op_counts = fill_invalid(start_time.month)\n",
    "\n",
    "    # Generate and run GRAPE study\n",
    "    print(\"Generating GRAPE file...\")\n",
    "    default_name = f\"{airport}_{start_time_str}_{stop_time_str}\"\n",
    "    path_study = (output_folder / default_name / default_name).with_suffix(\".grp\")\n",
    "    grape_traffic = GrapeTraffic(apt_traffic, \"data/EDDK 2019/receptors.csv\", study_path=path_study)\n",
    "    grape_traffic.generate_tables()\n",
    "    ops = grape_traffic.grape_tables[\"operations_tracks_4d\"]\n",
    "    if fill_invalid_flag:\n",
    "        ops = ops.merge(\n",
    "            op_counts,\n",
    "            how=\"left\",\n",
    "            left_on=\"id\",\n",
    "            right_index=True,\n",
    "            suffixes=(\"\", \"_new\"),\n",
    "        )\n",
    "        ops[\"count_new\"] = ops[\"count_new\"].fillna(0)\n",
    "        ops[\"count\"] += ops[\"count_new\"]\n",
    "        grape_traffic.grape_tables[\"operations_tracks_4d\"] = ops.drop(columns=[\"count_new\"])\n",
    "    grape_traffic.generate_grape()\n",
    "\n",
    "    # Run GRAPE\n",
    "    print(\"Running study...\")\n",
    "    grape_traffic.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions output\n",
    " \n",
    " Creates a *flights emissions.csv* file with columns:\n",
    " - `flight_id`\n",
    " - `duration`\n",
    " - `fuel`\n",
    " - `hc`\n",
    " - `co`\n",
    " - `nox`\n",
    " - `nvpm`\n",
    " - `nvpm_number`\n",
    " - `fuel_lto_cycle`\n",
    " - `hc_lto_cycle`\n",
    " - `co_lto_cycle`\n",
    " - `nox_lto_cycle`\n",
    " - `nvpm_lto_cycle`\n",
    " - `nvpm_number_lto_cycle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_time_str, stop_time_str in zip(start_times, stop_times):\n",
    "    start_time = pd.to_datetime(start_time_str).tz_localize(\"UTC\")\n",
    "    stop_time = pd.to_datetime(stop_time_str).tz_localize(\"UTC\")\n",
    "    start_time_str = start_time.strftime(\"%Y-%m-%d\")\n",
    "    stop_time_str = stop_time.strftime(\"%Y-%m-%d\")\n",
    "    default_name = f\"{airport}_{start_time_str}_{stop_time_str}\"\n",
    "    path_study = (output_folder / default_name / default_name).with_suffix(\".grp\")\n",
    "\n",
    "    print(f\"Processing flights from {path_study}.\")\n",
    "    # Connections\n",
    "    con = sqlite3.connect(path_study)\n",
    "\n",
    "    # Read tables\n",
    "    emi_lto_cycle = pd.read_sql(\n",
    "        f\"SELECT operation_id, operation, segment_number, fuel, hc, co, nox, nvpm, nvpm_number FROM emissions_run_output_segments WHERE emissions_run_id = '{emissions_id_lto_cycle}'\",\n",
    "        con=con,\n",
    "    )\n",
    "    emi_segs = pd.read_sql(\n",
    "        f\"SELECT operation_id, operation, segment_number, fuel, hc, co, nox, nvpm, nvpm_number FROM emissions_run_output_segments WHERE emissions_run_id = '{emissions_id}'\",\n",
    "        con=con,\n",
    "    )\n",
    "    perf_pts = pd.read_sql(\n",
    "        f\"SELECT operation_id, point_number, time FROM performance_run_output_points WHERE scenario_id = '{scenario_id}'\",\n",
    "        con=con,\n",
    "    )\n",
    "\n",
    "    # LTO Cycle\n",
    "    vars = [\"fuel\", \"hc\", \"co\", \"nox\", \"nvpm\", \"nvpm_number\"]\n",
    "\n",
    "    emi_lto_cycle.loc[\n",
    "        (emi_lto_cycle[\"operation\"] == \"Arrival\") & emi_lto_cycle[\"segment_number\"].isin([2, 3]),\n",
    "        vars,\n",
    "    ] = 0\n",
    "    emi_lto_cycle.loc[\n",
    "        (emi_lto_cycle[\"operation\"] == \"Departure\") & (emi_lto_cycle[\"segment_number\"] == 1),\n",
    "        vars,\n",
    "    ] = 0\n",
    "    emi_lto_cycle = emi_lto_cycle.drop(columns=\"segment_number\")\n",
    "    agg = {}\n",
    "    agg[\"operation\"] = \"first\"\n",
    "    for var in vars:\n",
    "        agg[var] = \"sum\"\n",
    "    emi_lto_cycle = emi_lto_cycle.groupby(\"operation_id\").agg(agg)\n",
    "\n",
    "    # Segments\n",
    "    emi_segs_times = emi_segs[[\"operation_id\", \"segment_number\"]].merge(\n",
    "        perf_pts,\n",
    "        left_on=[\"operation_id\", \"segment_number\"],\n",
    "        right_on=[\"operation_id\", \"point_number\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    emi_segs_times[\"time\"] = pd.to_datetime(emi_segs_times[\"time\"], utc=True)\n",
    "\n",
    "    emi_segs = emi_segs.drop(columns=\"segment_number\").groupby(\"operation_id\").agg(agg)\n",
    "    emi_segs_times = emi_segs_times.groupby(\"operation_id\")[\"time\"].agg(lambda x: (x.max() - x.min()).total_seconds())\n",
    "\n",
    "    emi_segs = (\n",
    "        emi_segs.merge(emi_segs_times, on=\"operation_id\")\n",
    "        .drop(columns=[\"operation\"])\n",
    "        .rename(columns={\"time\": \"duration\"})[\n",
    "            [\n",
    "                \"duration\",\n",
    "                \"fuel\",\n",
    "                \"hc\",\n",
    "                \"co\",\n",
    "                \"nox\",\n",
    "                \"nvpm\",\n",
    "                \"nvpm_number\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Merge segments and LTO Cycle\n",
    "    emi = emi_segs.merge(\n",
    "        emi_lto_cycle.drop(columns=\"operation\"),\n",
    "        on=\"operation_id\",\n",
    "        suffixes=(\"\", \"_lto_cycle\"),\n",
    "    )\n",
    "    emi = emi.rename(columns={\"operation_id\": \"flight_id\"})\n",
    "\n",
    "    # Write to .csv\n",
    "    header = not path_flights_emissions.exists()\n",
    "    emi.to_csv(path_flights_emissions, header=header, mode=\"a\")\n",
    "\n",
    "    # Close connections\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Output\n",
    "\n",
    " Creates a *flights noise.csv* file with columns:\n",
    " - `flight_id`\n",
    " - `receptor_id`\n",
    " - `count`\n",
    " - `lamax`\n",
    " - `sel`\n",
    " - `energy`\n",
    "\n",
    " Noise events below the thresholds defined by the airport will be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_time_str, stop_time_str in zip(start_times, stop_times):\n",
    "    start_time = pd.to_datetime(start_time_str).tz_localize(\"UTC\")\n",
    "    stop_time = pd.to_datetime(stop_time_str).tz_localize(\"UTC\")\n",
    "    start_time_str = start_time.strftime(\"%Y-%m-%d\")\n",
    "    stop_time_str = stop_time.strftime(\"%Y-%m-%d\")\n",
    "    default_name = f\"{airport}_{start_time_str}_{stop_time_str}\"\n",
    "    path_study = (output_folder / default_name / default_name).with_suffix(\".grp\")\n",
    "\n",
    "    # Connections\n",
    "    con = sqlite3.connect(path_study)\n",
    "\n",
    "    ns = pd.read_sql(\n",
    "        f\"SELECT t1.operation_id, t1.receptor_id, t1.maximum_db, t1.exposure_db, t2.time, t2.count \"\n",
    "        f\"FROM noise_run_output_single_event t1 JOIN operations_tracks_4d t2 ON t1.operation_id = t2.id \"\n",
    "        f\"WHERE \"\n",
    "        f\"t1.scenario_id = '{scenario_id}' AND \"\n",
    "        f\"t1.performance_run_id = '{performance_id}' AND \"\n",
    "        f\"t1.noise_run_id = '{noise_id}'\",\n",
    "        con=con,\n",
    "    )\n",
    "    ns[\"time\"] = pd.to_datetime(ns[\"time\"], utc=True)\n",
    "\n",
    "    # Delete events based on thresholds\n",
    "    thresholds = pd.read_excel(path_noise_thresholds, usecols=\"A:B\")\n",
    "    ns = pd.merge(ns, thresholds, how=\"left\", on=\"receptor_id\")\n",
    "    ns = ns.loc[~((ns[\"constant\"] == \"yes\") & (ns[\"maximum_db\"] < 65.0))]\n",
    "    day = (ns[\"time\"].dt.hour >= 6) & (ns[\"time\"].dt.hour <= 22)\n",
    "    ns = ns.loc[~((ns[\"constant\"] == \"no\") & day & (ns[\"maximum_db\"] < 65.0))]\n",
    "    ns = ns.loc[~((ns[\"constant\"] == \"no\") & ~day & (ns[\"maximum_db\"] < 63.0))]\n",
    "\n",
    "    # Organize\n",
    "    ns = ns.drop(columns=[\"time\", \"constant\"]).rename(\n",
    "        columns={\n",
    "            \"operation_id\": \"flight_id\",\n",
    "            \"maximum_db\": \"lamax\",\n",
    "            \"exposure_db\": \"sel\",\n",
    "        }\n",
    "    )[[\"flight_id\", \"receptor_id\", \"count\", \"lamax\", \"sel\"]]\n",
    "\n",
    "    # Write to .csv\n",
    "    header = not path_noise_events.exists()\n",
    "    ns.to_csv(path_noise_events, header=header, mode=\"a\", index=False)\n",
    "\n",
    "    # Close connections\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(path_flights_emissions)\n",
    "d = d.merge(\n",
    "    pd.read_csv(path_flights_clean, usecols=[\"flight_id\", \"operation\", \"aircraft_id\"]),\n",
    "    left_on=\"operation_id\",\n",
    "    right_on=\"flight_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "d = d.loc[d[\"aircraft_id\"].isin(d[\"aircraft_id\"].value_counts().head(5).index)]\n",
    "d[\"hc\"] *= 1000  # kg2g\n",
    "d[\"duration\"] /= 60  # sec 2 min\n",
    "d[\"hc_lto_cycle\"] *= 1000  # kg2g\n",
    "d[\"co\"] *= 1000  # kg2g\n",
    "d[\"co_lto_cycle\"] *= 1000  # kg2g\n",
    "d[\"nox\"] *= 1000  # kg2g\n",
    "d[\"nox_lto_cycle\"] *= 1000  # kg2g\n",
    "d[\"nvpm\"] *= 1e6  # kg2mg\n",
    "d[\"nvpm_lto_cycle\"] *= 1e6  # kg2mg\n",
    "\n",
    "arr = d.loc[d[\"operation\"] == \"Arrival\"]\n",
    "dep = d.loc[d[\"operation\"] == \"Departure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.groupby(\"aircraft_id\").mean(numeric_only=True).to_csv(\n",
    "    output_folder / \"flights emissions top10 arrival.csv\", float_format=\"%.2f\"\n",
    ")\n",
    "dep.groupby(\"aircraft_id\").mean(numeric_only=True).to_csv(\n",
    "    output_folder / \"out/flights emissions top10 departure.csv\",\n",
    "    float_format=\"%.2f\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.groupby(\"aircraft_id\").std(numeric_only=True).round(1).to_csv(\n",
    "    output_folder / \"flights emissions top5 arrival std rounded.csv\"\n",
    ")\n",
    "dep.groupby(\"aircraft_id\").std(numeric_only=True).round(1).to_csv(\n",
    "    output_folder / \"flights emissions top5 departure std rounded.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = arr.sum(numeric_only=True)\n",
    "print(f\"Arrival duration diff: {t['duration'] - 4.0 * len(arr)} min\")\n",
    "print(f\"Arrival fuel diff: {t['fuel'] - t['fuel_lto_cycle']} kg\")\n",
    "\n",
    "t = dep.sum(numeric_only=True)\n",
    "print(f\"Departure duration diff: {t['duration'] - 2.9 * len(dep)} min\")\n",
    "print(f\"Departure fuel diff: {t['fuel'] - t['fuel_lto_cycle']} kg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
